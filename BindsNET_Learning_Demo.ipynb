{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# BindsNET Learning Techniques\n",
    "\n",
    "## 1. Table of Contents\n",
    "1. Table of Contents\n",
    "2. Overview\n",
    "3. Import Statements\n",
    "4. Learning Rules\n",
    "    1. PostPre\n",
    "    2. Hebbian\n",
    "    3. WeightDependentPostPre\n",
    "    4. MSTDP\n",
    "    5. MSTDPET\n",
    "5. Custom Learning Rules\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 2. Overview\n",
    "\n",
    "Detail documentation of usage of learning rules has been specified [here] (https://bindsnet-docs.readthedocs.io/guide/guide_part_ii.html). This document will go into more specific examples of configuring a spiking neural network in BindsNET."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "The specified learning rule is passed into a `Connection` object via the `update_rule` argument.\n",
    "\n",
    "* `nu`: a 2-tuple pre- and post- synaptic learning rates (how quickly synapse weights change)\n",
    "* `reduction`: specifies how parameter updates are aggregated across the batch dimension\n",
    "* `weight_decay`: specifies the time constant of the rate of decay of synapse weights to zero\n",
    "* \n",
    "\n",
    "Parameter updates are averaged across the batch dimension by default, so there is no weight decay.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create two populations of neurons, one to act as the \"source\"\n",
    "# population, and the other, the \"target population\".\n",
    "# Neurons involved in certain learning rules must record synaptic\n",
    "# traces, a vector of short-term memories of the last emitted spikes.\n",
    "source_layer = Input(n=100, traces=True)\n",
    "target_layer = LIFNodes(n=1000, traces=True)\n",
    "\n",
    "# Connect the two layers.\n",
    "connection = Connection(\n",
    "    source=source_layer, target=target_layer, update_rule=PostPre, nu=(1e-4, 1e-2)\n",
    ")"
   ]
  },
  {
   "source": [
    "## 3. Import Statements"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from bindsnet.encoding import *\n",
    "from bindsnet.network import Network\n",
    "from bindsnet.network.monitors import Monitor\n",
    "from bindsnet.network.monitors import NetworkMonitor\n",
    "\n",
    "from bindsnet.analysis.plotting import plot_spikes, plot_voltages, plot_input, plot_weights\n",
    "\n",
    "from bindsnet.network.nodes import Input, LIFNodes\n",
    "from bindsnet.network.topology import Connection\n",
    "from bindsnet.learning import PostPre, Hebbian, WeightDependentPostPre, MSTDP, MSTDPET"
   ]
  },
  {
   "source": [
    "## 4. Learning Rules\n",
    "\n",
    "### 4a. PostPre\n",
    "\n",
    "Simple STDP rule involving both pre- and post-synaptic spiking activity. By default, pre-synaptic update is negative and the post-synaptic update is positive.\n",
    "\n",
    "| Parameters   | Type                                    | Description                                                                               | Default Value |\n",
    "|--------------|-----------------------------------------|-------------------------------------------------------------------------------------------|---------------|\n",
    "| connection   | AbstractConnection                      | An ``AbstractConnection`` object whose weights the ``PostPre`` learning rule will modify. |               |\n",
    "| nu           | Optional[Union[float, Sequence[float]]] | Single or pair of learning rates for pre- and post-synaptic events.                       | None          |\n",
    "| reduction    | Optional[callable]                      | Method for reducing parameter updates along the batch                                     | None          |\n",
    "| weight_decay | float                                   | Constant multiple to decay weights by on each iteration.                                  | 0.0           |"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize network\n",
    "network = Network()\n",
    "\n",
    "# set number of neurons\n",
    "input_neurons = 1\n",
    "lif_neurons = 1\n",
    "\n",
    "# simulation time\n",
    "time = 100\n",
    "dt = 1\n",
    "\n",
    "# configure weights for the synapses between the input layer and LIF layer\n",
    "w = torch.round(torch.abs(2 * torch.randn(input_neurons, lif_neurons)))\n",
    "\n",
    "# initialize input and LIF layers\n",
    "input_layer = Input(n=input_neurons)\n",
    "lif_layer = LIFNodes(n=lif_neurons)\n",
    "\n",
    "# connection between the input layer and the LIF layer\n",
    "connection = Connection(\n",
    "    source=input_layer, target=lif_layer, w=w, update_rule=PostPre, nu=(1e-4, 1e-2)\n",
    ")\n",
    "\n",
    "# create a monitor\n",
    "lif_layer_monitor = Monitor(\n",
    "    obj=lif_layer,\n",
    "    state_vars=(\"s\", \"v\"),  # Record spikes and voltages.\n",
    "    time=time,  # Length of simulation (if known ahead of time).\n",
    ")\n",
    "\n",
    "# add layers to network\n",
    "network.add_layer(\n",
    "    layer=input_layer, name=\"Input Layer\"\n",
    ")\n",
    "network.add_layer(\n",
    "    layer=lif_layer, name=\"LIF Layer\"\n",
    ")\n",
    "\n",
    "# add connection to network\n",
    "network.add_connection(\n",
    "    connection=connection, source=\"Input Layer\", target=\"LIF Layer\"\n",
    ")\n",
    "\n",
    "# add monitor to the network\n",
    "network.add_monitor(monitor=lif_layer_monitor, name=\"LIF Layer\")\n",
    "\n",
    "# create input spike data, where each spike is distributed according to Bernoulli(0.1)\n",
    "input_data = torch.bernoulli(0.1 * torch.ones(time, input_layer.n)).byte()\n",
    "encoded_image = input_data\n",
    "inputs = {\"Input Layer\": input_data}\n",
    "\n",
    "# simulate network on input data\n",
    "network.run(inputs=inputs, time=time)\n",
    "\n",
    "# retrieve and plot simulation spike, voltage data from monitors\n",
    "spikes = {\"LIF Layer\": lif_layer_monitor.get(\"s\")}\n",
    "voltages = {\"LIF Layer\": lif_layer_monitor.get(\"v\")}\n",
    "\n",
    "# plot spikes and voltages of the LIF layer\n",
    "# TODO: plot axes\n",
    "plot_spikes(spikes)\n",
    "plot_voltages(voltages, plot_type=\"line\")\n",
    "# plot_weights(w)\n",
    "\n",
    "# plot image\n",
    "# TODO: use a standard input image and encode it\n",
    "# e_img = encoded_image.view(int(time / dt), 1, 1, input_layer.n, 1)\n",
    "# inpt = e_img.view(int(time / dt), input_layer.n).sum(0).view(input_layer.n, 1)\n",
    "# plot_input(input_data,inpt)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "## 5. Custom Learning Rules"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Custom learning rules can be implemented by subclassing `bindsnet.learning.LearningRule` and providing implementations for the types of `AbstractConnection` objects intended to be used. \n",
    "\n",
    "For example, the `Connection` and `LocalConnection` objects rely on the implementation of a private method, `_connection_update`, whereas the `Conv2dConnection` object uses the `_conv2d_connection_update` version."
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}