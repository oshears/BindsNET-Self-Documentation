{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# BindsNET Learning Techniques\n",
    "\n",
    "## 1. Table of Contents\n",
    "1. Table of Contents\n",
    "2. Overview\n",
    "3. Import Statements\n",
    "4. Learning Flow\n",
    "5. Learning Rules\n",
    "    1. PostPre\n",
    "    2. Hebbian\n",
    "    3. WeightDependentPostPre\n",
    "    4. MSTDP\n",
    "    5. MSTDPET\n",
    "6. Custom Learning Rules\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 2. Overview\n",
    "\n",
    "Detail documentation of usage of learning rules has been specified [here] (https://bindsnet-docs.readthedocs.io/guide/guide_part_ii.html). This document will go into more specific examples of configuring a spiking neural network in BindsNET."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "The specified learning rule is passed into a `Connection` object via the `update_rule` argument. The connection encapsulates the learning rule object.\n",
    "\n",
    "* `nu`: a 2-tuple pre- and post- synaptic learning rates (how quickly synapse weights change)\n",
    "* `reduction`: specifies how parameter updates are aggregated across the batch dimension\n",
    "* `weight_decay`: specifies the time constant of the rate of decay of synapse weights to zero\n",
    "\n",
    "Parameter updates are averaged across the batch dimension by default, so there is no weight decay.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "from bindsnet.network.nodes import Input, LIFNodes\n",
    "from bindsnet.network.topology import Connection\n",
    "from bindsnet.learning import PostPre\n",
    "\n",
    "# Create two populations of neurons, one to act as the \"source\"\n",
    "# population, and the other, the \"target population\".\n",
    "# Neurons involved in certain learning rules must record synaptic\n",
    "# traces, a vector of short-term memories of the last emitted spikes.\n",
    "source_layer = Input(n=100, traces=True)\n",
    "target_layer = LIFNodes(n=1000, traces=True)\n",
    "\n",
    "# Connect the two layers.\n",
    "connection = Connection(\n",
    "    source=source_layer, target=target_layer, update_rule=PostPre, nu=(1e-4, 1e-2)\n",
    ")"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 105,
   "outputs": []
  },
  {
   "source": [
    "## 3. Import Statements"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "from bindsnet.encoding import *\n",
    "from bindsnet.network import Network\n",
    "from bindsnet.network.monitors import Monitor\n",
    "from bindsnet.network.monitors import NetworkMonitor\n",
    "\n",
    "from bindsnet.analysis.plotting import plot_spikes, plot_voltages, plot_input, plot_weights\n",
    "\n",
    "from bindsnet.network.nodes import Input, LIFNodes\n",
    "from bindsnet.network.topology import Connection\n",
    "from bindsnet.learning import PostPre, Hebbian, WeightDependentPostPre, MSTDP, MSTDPET\n",
    "\n",
    "from bindsnet.evaluation import all_activity, proportion_weighting, assign_labels\n",
    "from bindsnet.utils import get_square_weights, get_square_assignments"
   ]
  },
  {
   "source": [
    "## 4. Learning Flow\n",
    "\n",
    "1. Define simulation parameters\n",
    "2. Create input data\n",
    "3. Configure network architecture\n",
    "4. Define simulation variables\n",
    "5. Perform learning iterations\n",
    "6. Evaluate classification performance"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### 4.1 Simulation Parameters"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure number of input neurons\n",
    "input_layer_name = \"Input Layer\"\n",
    "input_neurons = 9\n",
    "\n",
    "# configure the number of output lif neurons\n",
    "lif_layer_name = \"LIF Layer\"\n",
    "lif_neurons = 2\n",
    "\n",
    "# set number of classes\n",
    "n_classes = 2\n",
    "\n",
    "# simulation time\n",
    "time = 100\n",
    "dt = 1\n",
    "\n",
    "# ratio of neurons to classes\n",
    "per_class = int(lif_neurons / n_classes)"
   ]
  },
  {
   "source": [
    "### 4.2 Input Configuration"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input data\n",
    "\n",
    "# initialize list of inputs\n",
    "imgs = []\n",
    "\n",
    "# Class 0 Image\n",
    "imgs += torch.flatten(torch.FloatTensor([[128,0,128],[0,128,0],[128,0,128]]))\n",
    "\n",
    "# Class 1 Image\n",
    "imgs += torch.flatten(torch.FloatTensor([[0,128,0],[128,128,128],[0,128,0]]))\n",
    "\n",
    "# initialize the encoder\n",
    "encoder = BernoulliEncoder(time=time, dt=dt)\n",
    "\n",
    "# list of encoded images for random selection during training\n",
    "encoded_inputs = []\n",
    "\n",
    "# loop through encode each image type and store into a list of encoded images\n",
    "for img in imgs:\n",
    "\n",
    "    # encode the image \n",
    "    encoded_img = encoder(img)\n",
    "\n",
    "    # add to the encoded input list along with the input layer name\n",
    "    encoded_inputs += {input_layer_name: encoded_img0}"
   ]
  },
  {
   "source": [
    "### 4.3 Network Configuration\n",
    "\n",
    "When creating a connection between two layers, the learning (update) rule should be specified as well as the learning rate (nu) "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize network\n",
    "network = Network()\n",
    "\n",
    "# configure weights for the synapses between the input layer and LIF layer\n",
    "w = torch.round(torch.abs(2 * torch.randn(input_neurons, lif_neurons)))\n",
    "\n",
    "# initialize input and LIF layers\n",
    "# spike traces must be recorded (why?)\n",
    "\n",
    "# initialize input layer\n",
    "input_layer = Input(n=input_neurons,traces=True)\n",
    "\n",
    "# initialize input layer\n",
    "lif_layer = LIFNodes(n=lif_neurons,traces=True)\n",
    "\n",
    "# initialize connection between the input layer and the LIF layer\n",
    "# specify the learning (update) rule and learning rate (nu)\n",
    "connection = Connection(\n",
    "    source=input_layer, target=lif_layer, w=w, update_rule=PostPre, nu=(1e-4, 1e-2)\n",
    ")\n",
    "\n",
    "# add input layer to the network\n",
    "network.add_layer(\n",
    "    layer=input_layer, name=input_layer_name\n",
    ")\n",
    "\n",
    "# add lif neuron layer to the network\n",
    "network.add_layer(\n",
    "    layer=lif_layer, name=lif_layer_name\n",
    ")\n",
    "\n",
    "# add connection to network\n",
    "network.add_connection(\n",
    "    connection=connection, source=input_layer_name, target=lif_layer_name\n",
    ")"
   ]
  },
  {
   "source": [
    "### 4.4 Simulation Variables"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# record the spike times of each neuron during the simulation.\n",
    "spike_record = torch.zeros(1, int(time / dt), lif_neurons)\n",
    "\n",
    "# record the mapping of each neuron to its corresponding label\n",
    "assignments = -torch.ones_like(torch.Tensor(lif_neurons))\n",
    "\n",
    "# \n",
    "rates = torch.zeros_like(torch.Tensor(lif_neurons, n_classes))\n",
    "\n",
    "# \n",
    "proportions = torch.zeros_like(torch.Tensor(lif_neurons, n_classes))\n",
    "\n",
    "\n",
    "# label(s) of the input(s) being processed\n",
    "labels = torch.empty(1,dtype=torch.int)\n",
    "\n",
    "# create a spike monitor for each layer in the network\n",
    "# this allows us to read the spikes in order to assign labels to neurons and determine the predicted class \n",
    "layer_monitors = {}\n",
    "for layer in set(network.layers):\n",
    "\n",
    "    # initialize spike monitor at the layer\n",
    "    # do not record the voltage if at the input layer\n",
    "    state_vars = [\"s\",\"v\"] if (layer != input_layer_name) else [\"s\"]\n",
    "    layer_monitors[layer] = Monitor(network.layers[layer], state_vars=state_vars, time=time)\n",
    "\n",
    "    # connect the monitor to the network\n",
    "    network.add_monitor(layer_monitors[layer], name=\"%s_spikes\" % layer)"
   ]
  },
  {
   "source": [
    "### 4.5 Training\n",
    "\n",
    "Below are descriptions of the functions required to train an SNN in BindsNET\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "`all_activity()`\n",
    "\n",
    "Classify data with the label with highest average spiking activity over all neurons.\n",
    "\n",
    "Returns a predictions tensor of shape `(n_samples,)` resulting from the \"all activity\" classification scheme (`torch.Tensor`)\n",
    "\n",
    "| Parameter  | Type         | Description                                                                           | Default Value |\n",
    "|-------------|--------------|---------------------------------------------------------------------------------------|---------|\n",
    "| spikes      | `torch.Tensor` | Binary tensor of shape `(n_samples, time, n_neurons)` of a layer'sspiking activity. |         |\n",
    "| assignments | `torch.Tensor` | A vector of shape `(n_neurons,)` of neuron label assignments.                       |         |\n",
    "| n_labels    | `int`          | The number of target labels in the data.                                              |         |\n",
    "\n",
    "\n",
    "----\n",
    "\n",
    "\n",
    "`proportion_weighting()`\n",
    "\n",
    "Classify data with the label with highest average spiking activity over all neurons, weighted by class-wise proportion.\n",
    "\n",
    "Returns a predictions tensor of shape `(n_samples,)` resulting from the \"proportion weighting\" classification scheme (`torch.Tensor`)\n",
    "\n",
    "| Parameter   | Type         | Description                                                                                              | Default Value |\n",
    "|-------------|--------------|----------------------------------------------------------------------------------------------------------|---------------|\n",
    "| spikes      | `torch.Tensor` | Binary tensor of shape `(n_samples, time, n_neurons)` of a single layer's spiking activity.            |               |\n",
    "| assignments | `torch.Tensor` | A vector of shape `(n_neurons,)` of neuron label assignments.                                          |               |\n",
    "| proportions | `torch.Tensor` | A matrix of shape `(n_neurons, n_labels)` giving the per-class proportions of neuron spiking activity. |               |\n",
    "| n_labels    | `int`          | The number of target labels in the data.                                                                 |               |\n",
    "\n",
    "----\n",
    "\n",
    "`assign_labels()`\n",
    "\n",
    "Assign labels to the neurons based on highest average spiking activity.\n",
    "\n",
    "Returns a Tuple of class assignments, per-class spike proportions, and per-class firing rates (`Tuple[torch.Tensor, torch.Tensor, torch.Tensor]`)\n",
    "\n",
    "| Parameter | Type                     | Descriptions                                                                                  | Default Value |  \n",
    "|------------|--------------------------|-----------------------------------------------------------------------------------------------|---------------|\n",
    "| spikes     | `torch.Tensor`             | Binary tensor of shape `(n_samples, time, n_neurons)` of a single layer's spiking activity. |                | \n",
    "| labels     | `torch.Tensor`             | Vector of shape `(n_samples,)` with data labels corresponding to spiking activity.          |                | \n",
    "| n_labels   | `int`                      | The number of target labels in the data.                                                      |                | \n",
    "| rates      | `Optional[torch.Tensor]` | If passed, these represent spike rates from a previous `assign_labels()` call.              | None          | \n",
    "| alpha      | `float`                    | Rate of decay of label assignments.                                                           | 1             | \n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Actual Label | Predicted Label [All Activity] | Predicted Label [Weighted Proportion]\n",
      "[1] | [1] | [1]\n",
      "Assignments:\n",
      "tensor([1, 1])\n",
      "Proportions:\n",
      "tensor([[0., 1.],\n",
      "        [0., 1.]])\n",
      "Rates:\n",
      "tensor([[  0.,   9.],\n",
      "        [  0., 100.]])\n",
      "Accuracy: 1.0\n",
      "====================\n",
      "\n",
      "\n",
      "Actual Label | Predicted Label [All Activity] | Predicted Label [Weighted Proportion]\n",
      "[1] | [1] | [1]\n",
      "Assignments:\n",
      "tensor([1, 1])\n",
      "Proportions:\n",
      "tensor([[0., 1.],\n",
      "        [0., 1.]])\n",
      "Rates:\n",
      "tensor([[  0.,  18.],\n",
      "        [  0., 200.]])\n",
      "Accuracy: 1.0\n",
      "====================\n",
      "\n",
      "\n",
      "Actual Label | Predicted Label [All Activity] | Predicted Label [Weighted Proportion]\n",
      "[1] | [1] | [1]\n",
      "Assignments:\n",
      "tensor([1, 1])\n",
      "Proportions:\n",
      "tensor([[0., 1.],\n",
      "        [0., 1.]])\n",
      "Rates:\n",
      "tensor([[  0.,  28.],\n",
      "        [  0., 300.]])\n",
      "Accuracy: 1.0\n",
      "====================\n",
      "\n",
      "\n",
      "Actual Label | Predicted Label [All Activity] | Predicted Label [Weighted Proportion]\n",
      "[1] | [1] | [1]\n",
      "Assignments:\n",
      "tensor([1, 1])\n",
      "Proportions:\n",
      "tensor([[0., 1.],\n",
      "        [0., 1.]])\n",
      "Rates:\n",
      "tensor([[  0.,  39.],\n",
      "        [  0., 400.]])\n",
      "Accuracy: 1.0\n",
      "====================\n",
      "\n",
      "\n",
      "Actual Label | Predicted Label [All Activity] | Predicted Label [Weighted Proportion]\n",
      "[0] | [0] | [0]\n",
      "Assignments:\n",
      "tensor([0, 1])\n",
      "Proportions:\n",
      "tensor([[0.7194, 0.2806],\n",
      "        [0.0361, 0.9639]])\n",
      "Rates:\n",
      "tensor([[100.,  39.],\n",
      "        [ 15., 400.]])\n",
      "Accuracy: 1.0\n",
      "====================\n",
      "\n",
      "\n",
      "Actual Label | Predicted Label [All Activity] | Predicted Label [Weighted Proportion]\n",
      "[1] | [1] | [1]\n",
      "Assignments:\n",
      "tensor([0, 1])\n",
      "Proportions:\n",
      "tensor([[0.6579, 0.3421],\n",
      "        [0.0291, 0.9709]])\n",
      "Rates:\n",
      "tensor([[100.,  52.],\n",
      "        [ 15., 500.]])\n",
      "Accuracy: 1.0\n",
      "====================\n",
      "\n",
      "\n",
      "Actual Label | Predicted Label [All Activity] | Predicted Label [Weighted Proportion]\n",
      "[0] | [0] | [0]\n",
      "Assignments:\n",
      "tensor([0, 1])\n",
      "Proportions:\n",
      "tensor([[0.7937, 0.2063],\n",
      "        [0.0602, 0.9398]])\n",
      "Rates:\n",
      "tensor([[200.,  52.],\n",
      "        [ 32., 500.]])\n",
      "Accuracy: 1.0\n",
      "====================\n",
      "\n",
      "\n",
      "Actual Label | Predicted Label [All Activity] | Predicted Label [Weighted Proportion]\n",
      "[0] | [0] | [0]\n",
      "Assignments:\n",
      "tensor([0, 1])\n",
      "Proportions:\n",
      "tensor([[0.8523, 0.1477],\n",
      "        [0.0893, 0.9107]])\n",
      "Rates:\n",
      "tensor([[300.,  52.],\n",
      "        [ 49., 500.]])\n",
      "Accuracy: 1.0\n",
      "====================\n",
      "\n",
      "\n",
      "Actual Label | Predicted Label [All Activity] | Predicted Label [Weighted Proportion]\n",
      "[0] | [0] | [0]\n",
      "Assignments:\n",
      "tensor([0, 1])\n",
      "Proportions:\n",
      "tensor([[0.8850, 0.1150],\n",
      "        [0.1150, 0.8850]])\n",
      "Rates:\n",
      "tensor([[400.,  52.],\n",
      "        [ 65., 500.]])\n",
      "Accuracy: 1.0\n",
      "====================\n",
      "\n",
      "\n",
      "Actual Label | Predicted Label [All Activity] | Predicted Label [Weighted Proportion]\n",
      "[0] | [0] | [0]\n",
      "Assignments:\n",
      "tensor([0, 1])\n",
      "Proportions:\n",
      "tensor([[0.9058, 0.0942],\n",
      "        [0.1409, 0.8591]])\n",
      "Rates:\n",
      "tensor([[500.,  52.],\n",
      "        [ 82., 500.]])\n",
      "Accuracy: 1.0\n",
      "====================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weight_history = None\n",
    "first_pass = True\n",
    "plot_weights = False\n",
    "num_correct = 0.0\n",
    "epochs = 10\n",
    "\n",
    "# simulate network on input data\n",
    "# iterate for epochs\n",
    "for step in range(epochs):\n",
    "\n",
    "    # randomly select and input image class\n",
    "    labels[0] = random.randint(0,n_classes-1)\n",
    "\n",
    "    choice = np.random.choice(int(lif_neurons / n_classes), size=1, replace=False)\n",
    "\n",
    "    # clamp: Mapping of layer names to boolean masks if neurons should be clamped to spiking. \n",
    "    # The ``Tensor``s have shape ``[n_neurons]`` or ``[time, n_neurons]``.\n",
    "    # clamp on the output layer (Ae), forces the node corresponding to the label's class to spike\n",
    "    clamp = {lif_layer_name: per_class * labels[0] + torch.Tensor(choice).long()}\n",
    "\n",
    "    # get the input image from the list of encoded inputs\n",
    "    inputs = encoded_inputs[labels[0]]\n",
    "\n",
    "    ### Step 1: Run the network with the provided inputs ###\n",
    "    network.run(inputs=inputs, time=time, clamp=clamp)\n",
    "\n",
    "    ### Step 2: Get the spikes produced at the output layer ###\n",
    "    spike_record[0] = layer_monitors[lif_layer_name].get(\"s\").view(time, lif_neurons)\n",
    "    \n",
    "    ### Step 3: ###\n",
    "\n",
    "    # Assign labels to the neurons based on highest average spiking activity.\n",
    "    # Returns a Tuple of class assignments, per-class spike proportions, and per-class firing rates \n",
    "    # Return Type: Tuple[torch.Tensor, torch.Tensor, torch.Tensor]\n",
    "    assignments, proportions, rates = assign_labels( spike_record, labels, n_classes, rates )\n",
    "\n",
    "    ### Step 4: Classify data based on the neuron (label) with the highest average spiking activity ###\n",
    "\n",
    "    # Classify data with the label with highest average spiking activity over all neurons.\n",
    "    all_activity_pred = all_activity(spike_record, assignments, n_classes)\n",
    "\n",
    "    ### Step 5: Classify data based on the neuron (label) with the highest average spiking activity, weighted by class-wise proportion ###\n",
    "    proportion_pred = proportion_weighting(spike_record, assignments, proportions, n_classes)\n",
    "\n",
    "    ### Update Accuracy\n",
    "    num_correct += 1 if (labels.numpy()[0] == all_activity_pred.numpy()[0]) else 0\n",
    "\n",
    "    ######## Display Information ########\n",
    "    print(\"Actual Label | Predicted Label [All Activity] | Predicted Label [Weighted Proportion]\")\n",
    "    print(labels.numpy(),\"|\",all_activity_pred.numpy(),\"|\",proportion_pred.numpy())\n",
    "    print(\"Assignments:\")\n",
    "    print(assignments)\n",
    "\n",
    "    print(\"Proportions:\")\n",
    "    print(proportions)\n",
    "\n",
    "    print(\"Rates:\")\n",
    "    print(rates)\n",
    "    #####################################\n",
    "\n",
    "\n",
    "    ### For Weight Plotting ###\n",
    "    if plot_weights:\n",
    "        weights = network.connections[(\"Input Layer\", \"LIF Layer\")].w[:,0].numpy().reshape((1,input_neurons))\n",
    "        weight_history = weights.copy() if first_pass else np.concatenate((weight_history,weights),axis=0)\n",
    "    first_pass = False\n",
    "    #############################\n",
    "\n",
    "    print(\"Accuracy:\", num_correct / (step + 1.0) )\n",
    "\n",
    "    print(\"====================\\n\\n\")\n",
    "\n",
    "### For Weight Plotting ###\n",
    "# Plot Weight Changes\n",
    "if plot_weights:\n",
    "    [plt.plot(weight_history[:,idx]) for idx in range(weight_history.shape[1])]\n",
    "    plt.show()\n",
    "#############################"
   ]
  },
  {
   "source": [
    "### 4.6 Evaluate Performance"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through each test example and record performance"
   ]
  },
  {
   "source": [
    "## 5. Learning Rules\n",
    "\n",
    "### 5a. PostPre\n",
    "\n",
    "Simple STDP rule involving both pre- and post-synaptic spiking activity. By default, pre-synaptic update is negative and the post-synaptic update is positive.\n",
    "\n",
    "| Parameters   | Type                                    | Description                                                                               | Default Value |\n",
    "|--------------|-----------------------------------------|-------------------------------------------------------------------------------------------|---------------|\n",
    "| connection   | AbstractConnection                      | An `AbstractConnection` object whose weights the `PostPre` learning rule will modify. |               |\n",
    "| nu           | Optional\\[Union\\[float, Sequence\\[float]]] | Single or pair of learning rates for pre- and post-synaptic events.                       | None          |\n",
    "| reduction    | Optional\\[callable]                      | Method for reducing parameter updates along the batch                                     | None          |\n",
    "| weight_decay | float                                   | Constant multiple to decay weights by on each iteration.                                  | 0.0           |"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 6. Custom Learning Rules"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Custom learning rules can be implemented by subclassing `bindsnet.learning.LearningRule` and providing implementations for the types of `AbstractConnection` objects intended to be used. \n",
    "\n",
    "For example, the `Connection` and `LocalConnection` objects rely on the implementation of a private method, `_connection_update`, whereas the `Conv2dConnection` object uses the `_conv2d_connection_update` version."
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}