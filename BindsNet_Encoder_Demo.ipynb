{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.7.7 64-bit",
   "display_name": "Python 3.7.7 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "ce5e766d682db6f5488faddea2f1c1fe3f8f2a79a4884d4520d9debb7dff6d09"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# BindsNet Encoders\n",
    "\n",
    "## 1. Table of Contents\n",
    "1. Table of Contents\n",
    "2. Overview\n",
    "2. Import Statements\n",
    "3. Encoders\n",
    "    1. Single Spike Encoders\n",
    "    2. Repeat Encoder\n",
    "    3. Poisson Encoders\n",
    "    4. Bernoulli Encoders\n",
    "    5. Rank Order Encoder\n",
    "\n",
    "## 2. Overview\n",
    "All of the encoders below transform an N dimensional input tensor into an N + 1 dimensional tensor, where the added dimension is time. The data fed into the encoders must all be floating point values. This is because some of the encoders perform divisions using the data that could approximate to fractional values."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 2. Import Statements"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from time import time as t\n",
    "\n",
    "from bindsnet.encoding import *"
   ]
  },
  {
   "source": [
    "## 3a. Single (Spike) Encoder\n",
    "### Summary\n",
    "The single (spike) encoder transforms the data into a tensor where the value at time 0 in the tensor for a given element in the input has a spike if the value is greater than the quantile cutoff. The closer to 1 the sparsity is, the more spikes will be permitted. A value of 0 means no spikes will be permitted.\n",
    "### Quantile Calculation\n",
    "For Numpy, the quantile is calculated as:\n",
    "```\n",
    "np.quantile(np.array([4, 3, 2, 1]),0) \n",
    "1\n",
    "np.quantile(np.array([4, 3, 2, 1]),0.25) \n",
    "1.75\n",
    "np.quantile(np.array([4, 3, 2, 1]),0.50) \n",
    "2.5\n",
    "np.quantile(np.array([4, 3, 2, 1]),0.75) \n",
    "3.25\n",
    "np.quantile(np.array([4, 3, 2, 1]),1) \n",
    "4\n",
    "```"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Input Datum:\ntensor([[80., 70., 60.],\n        [50., 40., 30.],\n        [20., 10.,  0.]])\nEncoded Datum w/ Sparsity of 0.25:\ntensor([[[1, 1, 0],\n         [0, 0, 0],\n         [0, 0, 0]]], dtype=torch.uint8)\nEncoded Datum w/ Sparsity of 0.5:\ntensor([[[1, 1, 1],\n         [1, 0, 0],\n         [0, 0, 0]]], dtype=torch.uint8)\nEncoded Datum w/ Sparsity of 0.75:\ntensor([[[1, 1, 1],\n         [1, 1, 1],\n         [0, 0, 0]]], dtype=torch.uint8)\nEncoded Datum w/ Sparsity of 1:\ntensor([[[1, 1, 1],\n         [1, 1, 1],\n         [1, 1, 0]]], dtype=torch.uint8)\n"
     ]
    }
   ],
   "source": [
    "# time is the total sample duration in ms\n",
    "# set to 1 for this example because steps after the first will not generate spikes\n",
    "time = 1\n",
    "\n",
    "# dt is the step size within the sample duration in ms\n",
    "dt = 1.0\n",
    "\n",
    "# input data\n",
    "train_image = torch.FloatTensor([[80,70,60],[50,40,30],[20,10,0]])\n",
    "\n",
    "# print train data\n",
    "print(\"Input Datum:\")\n",
    "print(train_image)\n",
    "\n",
    "# sparsity of spikes (1 for all spikes, 0 for no spikes)\n",
    "\n",
    "# spikes over the 0.75 quantile will be permitted\n",
    "sparsity = 0.25\n",
    "encoder = SingleEncoder(time=time, dt=dt,sparsity=sparsity)\n",
    "encoded_image = encoder(train_image)\n",
    "print(\"Encoded Datum w/ Sparsity of 0.25:\")\n",
    "print(encoded_image)\n",
    "\n",
    "# spikes over the 0.5 quantile will be permitted\n",
    "sparsity = 0.5\n",
    "encoder = SingleEncoder(time=time, dt=dt,sparsity=sparsity)\n",
    "encoded_image = encoder(train_image)\n",
    "print(\"Encoded Datum w/ Sparsity of 0.5:\")\n",
    "print(encoded_image)\n",
    "\n",
    "# spikes over the 0.25 quantile will be permitted\n",
    "sparsity = 0.75\n",
    "encoder = SingleEncoder(time=time, dt=dt,sparsity=sparsity)\n",
    "encoded_image = encoder(train_image)\n",
    "print(\"Encoded Datum w/ Sparsity of 0.75:\")\n",
    "print(encoded_image)\n",
    "\n",
    "# all spikes will be permitted\n",
    "sparsity = 1\n",
    "encoder = SingleEncoder(time=time, dt=dt,sparsity=sparsity)\n",
    "encoded_image = encoder(train_image)\n",
    "print(\"Encoded Datum w/ Sparsity of 1:\")\n",
    "print(encoded_image)"
   ]
  },
  {
   "source": [
    "## 3b. Repeat Encoder\n",
    "### Summary\n",
    "Repeats the same datum vector for `time/dt` timesteps\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Input Datum:\ntensor([[80., 70., 60.],\n        [50., 40., 30.],\n        [20., 10.,  0.]])\nEncoded Datum:\ntensor([[[80., 70., 60.],\n         [50., 40., 30.],\n         [20., 10.,  0.]],\n\n        [[80., 70., 60.],\n         [50., 40., 30.],\n         [20., 10.,  0.]],\n\n        [[80., 70., 60.],\n         [50., 40., 30.],\n         [20., 10.,  0.]]])\n"
     ]
    }
   ],
   "source": [
    "# time is the total sample duration in ms\n",
    "time = 3\n",
    "\n",
    "# dt is the step size within the sample duration in ms\n",
    "dt = 1.0\n",
    "\n",
    "# input data\n",
    "train_image = torch.FloatTensor([[80,70,60],[50,40,30],[20,10,0]])\n",
    "\n",
    "# print train data\n",
    "print(\"Input Datum:\")\n",
    "print(train_image)\n",
    "\n",
    "# create encoder and encode input\n",
    "encoder = RepeatEncoder(time=time, dt=dt)\n",
    "train_image = torch.FloatTensor([[80,70,60],[50,40,30],[20,10,0]])\n",
    "encoded_image = encoder(train_image)\n",
    "print(\"Encoded Datum:\")\n",
    "print(encoded_image)"
   ]
  },
  {
   "source": [
    "## 3c. Poisson Encoder\n",
    "\n",
    "### Summary\n",
    "Generates Poisson-distributed spike trains based on input intensity. Inputs must be non-negative, and give the firing rate in Hz. Inter-spike intervals (ISIs) for non-negative data incremented by one to avoid zero intervals while maintaining ISI distributions.\n",
    "\n",
    "### Limitations\n",
    "* Inputs must be non-negative\n",
    "* Inputs must be floating point numbers (otherwise the rate will zero out)\n",
    "\n",
    "### Rate Calculation\n",
    "\n",
    "1. Compute firing rates in seconds as a function of data intensity\n",
    "    * rate = (1 / input_intensity) * (1000 / dt)\n",
    "    * higher intensity -> lower inter-spike interaval\n",
    "    * dt = simulation time step\n",
    "2. Create Poisson distribution and sample inter-spike intervals\n",
    "    * `torch.distributions.Poisson()` used to generate samples\n",
    "    * `time/dt` samples are taken for each input element based on the probability density function (pdf) of a Poisson distribution\n",
    "        * Vales near the rate (lambda) more likely to occur\n",
    "        * The higher the rate, the more varied the data will be\n",
    "    * if any samples produced 0, set them to 1\n",
    "3. Incrementally add all of the samples generated for each input element\n",
    "    * this produces indexes of where to set the spike outputs for each element in the spikes array\n",
    "    * if any samples are greater than `time/dt`, set them to 0 because they are outside of the sample duration\n",
    "4. Create tensor of spikes\n",
    "    * for each of the indexes produced, set the corresponding indexes in the spike tensor to 1\n",
    "    * given an input tensor with dimsnions X x Y, the output tensor has dimensions (time/dt + 1) x X x Y\n",
    "    * remove the first row of spikes because they are all set to 1\n",
    "\n",
    "\n",
    "### Poisson Distribution\n",
    "\n",
    "![Poisson Probability Function](https://wikimedia.org/api/rest_v1/media/math/render/svg/c22cb4461e100a6db5f815de1f44b1747f160048)\n",
    "\n",
    "![Poisson Probability Graph Function](https://upload.wikimedia.org/wikipedia/commons/thumb/1/16/Poisson_pmf.svg/325px-Poisson_pmf.svg.png)\n",
    "\n",
    "where\n",
    "* k is the number of occurrences\n",
    "* Î» is the rate (mean number of occurrences in the interval)\n",
    "\n",
    "(Source [wikipedia.org](https://en.wikipedia.org/wiki/Poisson_distribution))"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Input Datum:\ntensor([[80., 70., 60.],\n        [50., 40., 30.],\n        [20., 10.,  0.]])\nEncoded Datum:\ntensor([[[0, 0, 0],\n         [0, 0, 0],\n         [0, 0, 0]],\n\n        [[0, 0, 0],\n         [0, 0, 0],\n         [0, 0, 0]],\n\n        [[0, 0, 0],\n         [0, 0, 0],\n         [0, 0, 0]],\n\n        [[0, 0, 0],\n         [0, 0, 0],\n         [0, 0, 0]],\n\n        [[0, 0, 0],\n         [0, 0, 0],\n         [0, 0, 0]],\n\n        [[0, 0, 0],\n         [0, 0, 0],\n         [0, 0, 0]],\n\n        [[1, 0, 0],\n         [0, 0, 0],\n         [0, 0, 0]],\n\n        [[0, 0, 0],\n         [0, 0, 0],\n         [0, 0, 0]],\n\n        [[0, 0, 0],\n         [0, 0, 0],\n         [0, 0, 0]],\n\n        [[0, 0, 0],\n         [0, 0, 0],\n         [0, 0, 0]]], dtype=torch.uint8)\n"
     ]
    }
   ],
   "source": [
    "# time is the total sample duration in ms\n",
    "time = 10\n",
    "\n",
    "# dt is the step size within the sample duration in ms\n",
    "dt = 1.0\n",
    "\n",
    "# input data\n",
    "train_image = torch.FloatTensor([[80,70,60],[50,40,30],[20,10,0]])\n",
    "\n",
    "# print train data\n",
    "print(\"Input Datum:\")\n",
    "print(train_image)\n",
    "\n",
    "# create encoder and encode input\n",
    "encoder = PoissonEncoder(time=time, dt=dt)\n",
    "encoded_image = encoder(train_image)\n",
    "print(\"Encoded Datum:\")\n",
    "print(encoded_image)"
   ]
  },
  {
   "source": [
    "## 3d. Bernoulli Encoder\n",
    "### Summary\n",
    "Generates Bernoulli-distributed spike trains based on input intensity. Inputs must be non-negative. Spikes correspond to successful Bernoulli trials, with success probability equal to (normalized in \\[0, 1]) input value.\n",
    "\n",
    "### Limitations\n",
    "* Inputs must be non-negative\n",
    "* Inputs must be floating point numbers (otherwise the rate will zero out)\n",
    "\n",
    "### Bernoulli Trial Calculation\n",
    "1. Inputs are normalized based on the max intensity\n",
    "    * The highest intensity will have a probability of 1 and always spike\n",
    "    * An intensity of 0 will have a probability of 0 and never spike\n",
    "2. The spike tensor is generated using `torch.bernoulli()` to generate the random samples\n",
    "    * Highest intensity will always produce 1, lower intensities will generate 1's based on their scale against the highest intensity"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[80., 70., 60.],\n        [50., 40., 30.],\n        [20., 10.,  0.]])\ntensor([[[1, 1, 1],\n         [1, 0, 0],\n         [0, 0, 0]],\n\n        [[1, 1, 0],\n         [1, 1, 1],\n         [0, 0, 0]],\n\n        [[1, 1, 1],\n         [0, 0, 0],\n         [0, 0, 0]],\n\n        [[1, 1, 1],\n         [0, 1, 1],\n         [1, 0, 0]],\n\n        [[1, 1, 1],\n         [0, 1, 0],\n         [1, 1, 0]],\n\n        [[1, 1, 1],\n         [1, 1, 1],\n         [0, 1, 0]],\n\n        [[1, 1, 1],\n         [0, 0, 1],\n         [1, 1, 0]],\n\n        [[1, 1, 1],\n         [0, 0, 0],\n         [1, 0, 0]],\n\n        [[1, 1, 1],\n         [1, 1, 1],\n         [0, 0, 0]],\n\n        [[1, 1, 0],\n         [1, 1, 0],\n         [0, 0, 0]]], dtype=torch.uint8)\n"
     ]
    }
   ],
   "source": [
    "# time is the total sample duration in ms\n",
    "time = 10\n",
    "\n",
    "# dt is the step size within the sample duration in ms\n",
    "dt = 1.0\n",
    "\n",
    "# input data\n",
    "train_image = torch.FloatTensor([[80,70,60],[50,40,30],[20,10,0]])\n",
    "\n",
    "# print train data\n",
    "print(train_image)\n",
    "\n",
    "# create encoder and encode input\n",
    "encoder = BernoulliEncoder(time=time, dt=dt)\n",
    "encoded_image = encoder(train_image)\n",
    "print(encoded_image)"
   ]
  },
  {
   "source": [
    "## 3e. Rank Order Encoder\n",
    "* data with the same value will spike at the same time\n",
    "* first: data scaled based on the max value\n",
    "* times array created with highest value having value of 1 and lowest value closer to inf\n",
    "* time array multiplied by num timesteps / max value in time array\n",
    "* values are rounded up to next whole number\n",
    "* spike array created n elements for each timestep\n",
    "* iterate through each element i\n",
    "* if the rank for i is within the time number of timesteps\n",
    "* add a spike for this element wherever the spike is supposed to occur\n",
    "* the close the data is to 0, the higher (later) the rank will be"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[80., 70., 60.],\n        [50., 40., 30.],\n        [20., 10.,  0.]])\ntensor([[[0, 0, 0],\n         [0, 0, 0],\n         [0, 0, 0]],\n\n        [[1, 1, 1],\n         [1, 0, 0],\n         [0, 0, 0]],\n\n        [[0, 0, 0],\n         [0, 1, 0],\n         [0, 0, 0]],\n\n        [[0, 0, 0],\n         [0, 0, 1],\n         [0, 0, 0]],\n\n        [[0, 0, 0],\n         [0, 0, 0],\n         [1, 0, 0]],\n\n        [[0, 0, 0],\n         [0, 0, 0],\n         [0, 0, 0]],\n\n        [[0, 0, 0],\n         [0, 0, 0],\n         [0, 0, 0]],\n\n        [[0, 0, 0],\n         [0, 0, 0],\n         [0, 0, 0]],\n\n        [[0, 0, 0],\n         [0, 0, 0],\n         [0, 0, 0]],\n\n        [[0, 0, 0],\n         [0, 0, 0],\n         [0, 0, 0]]], dtype=torch.uint8)\n"
     ]
    }
   ],
   "source": [
    "# time is the total sample duration in ms\n",
    "time = 10\n",
    "\n",
    "# dt is the step size within the sample duration in ms\n",
    "dt = 1.0\n",
    "\n",
    "# input data\n",
    "train_image = torch.FloatTensor([[80,70,60],[50,40,30],[20,10,0]])\n",
    "\n",
    "# print train data\n",
    "print(train_image)\n",
    "\n",
    "# create encoder and encode input\n",
    "encoder = RankOrderEncoder(time=time, dt=dt)\n",
    "encoded_image = encoder(train_image)\n",
    "print(encoded_image)"
   ]
  }
 ]
}