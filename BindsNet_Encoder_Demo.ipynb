{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.6 64-bit",
   "display_name": "Python 3.8.6 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "ebf2dfc5f496702d4c934e945866756ff8cc31738b9b3e43d59703c5394ea397"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# BindsNet Encoders\n",
    "\n",
    "## 1. Table of Contents\n",
    "1. Table of Contents\n",
    "2. Overview\n",
    "2. Import Statements\n",
    "3. Encoders\n",
    "    1. Single Spike Encoders\n",
    "    2. Repeat Encoder\n",
    "    3. Poisson Encoders\n",
    "    4. Bernoulli Encoders\n",
    "    5. Rank Order Encoder\n",
    "\n",
    "## 2. Overview\n",
    "All of the encoders below transform an N dimensional input tensor into an N + 1 dimensional tensor, where the added dimension is time. The data fed into the encoders must all be floating point values. This is because some of the encoders perform divisions using the data that could approximate to fractional values."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 2. Import Statements"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from time import time as t\n",
    "\n",
    "from bindsnet.encoding import *"
   ]
  },
  {
   "source": [
    "## 3a. Single (Spike) Encoder\n",
    "The single (spike) encoder transforms the data into a tensor where the value at time 0 in the tensor for a given element in the input has a spike if the value is greater than the quantile cutoff. The closer to 1 the sparsity is, the more spikes will be permitted. A value of 0 means no spikes will be permitted.\n",
    "\n",
    "For Numpy, the quantile is calculated as:\n",
    "```\n",
    "np.quantile(np.array([4, 3, 2, 1]),0) \n",
    "1\n",
    "np.quantile(np.array([4, 3, 2, 1]),0.25) \n",
    "1.75\n",
    "np.quantile(np.array([4, 3, 2, 1]),0.50) \n",
    "2.5\n",
    "np.quantile(np.array([4, 3, 2, 1]),0.75) \n",
    "3.25\n",
    "np.quantile(np.array([4, 3, 2, 1]),1) \n",
    "4\n",
    "```"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[80., 70., 60.],\n        [50., 40., 30.],\n        [20., 10.,  0.]])\ntensor([[[1, 1, 0],\n         [0, 0, 0],\n         [0, 0, 0]]], dtype=torch.uint8)\ntensor([[[1, 1, 1],\n         [1, 0, 0],\n         [0, 0, 0]]], dtype=torch.uint8)\ntensor([[[1, 1, 1],\n         [1, 1, 1],\n         [0, 0, 0]]], dtype=torch.uint8)\ntensor([[[1, 1, 1],\n         [1, 1, 1],\n         [1, 1, 0]]], dtype=torch.uint8)\n"
     ]
    }
   ],
   "source": [
    "# time is the total sample duration in ms\n",
    "# set to 1 for this example because steps after the first will not generate spikes\n",
    "time = 1\n",
    "\n",
    "# dt is the step size within the sample duration in ms\n",
    "dt = 1.0\n",
    "\n",
    "# input data\n",
    "train_image = torch.FloatTensor([[80,70,60],[50,40,30],[20,10,0]])\n",
    "\n",
    "# print train data\n",
    "print(train_image)\n",
    "\n",
    "# sparsity of spikes (1 for all spikes, 0 for no spikes)\n",
    "\n",
    "# spikes over the 0.75 quantile will be permitted\n",
    "sparsity = 0.25\n",
    "encoder = SingleEncoder(time=time, dt=dt,sparsity=sparsity)\n",
    "encoded_image = encoder(train_image)\n",
    "print(encoded_image)\n",
    "\n",
    "# spikes over the 0.5 quantile will be permitted\n",
    "sparsity = 0.5\n",
    "encoder = SingleEncoder(time=time, dt=dt,sparsity=sparsity)\n",
    "encoded_image = encoder(train_image)\n",
    "print(encoded_image)\n",
    "\n",
    "# spikes over the 0.25 quantile will be permitted\n",
    "sparsity = 0.75\n",
    "encoder = SingleEncoder(time=time, dt=dt,sparsity=sparsity)\n",
    "encoded_image = encoder(train_image)\n",
    "print(encoded_image)\n",
    "\n",
    "# all spikes will be permitted\n",
    "sparsity = 1\n",
    "encoder = SingleEncoder(time=time, dt=dt,sparsity=sparsity)\n",
    "encoded_image = encoder(train_image)\n",
    "print(encoded_image)"
   ]
  },
  {
   "source": [
    "## 3b. Repeat Encoder\n",
    "Repeats the same datum vector for time/dt timesteps\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[80., 70., 60.],\n        [50., 40., 30.],\n        [20., 10.,  0.]])\ntensor([[[80., 70., 60.],\n         [50., 40., 30.],\n         [20., 10.,  0.]],\n\n        [[80., 70., 60.],\n         [50., 40., 30.],\n         [20., 10.,  0.]],\n\n        [[80., 70., 60.],\n         [50., 40., 30.],\n         [20., 10.,  0.]]])\n"
     ]
    }
   ],
   "source": [
    "# time is the total sample duration in ms\n",
    "time = 3\n",
    "\n",
    "# dt is the step size within the sample duration in ms\n",
    "dt = 1.0\n",
    "\n",
    "# input data\n",
    "train_image = torch.FloatTensor([[80,70,60],[50,40,30],[20,10,0]])\n",
    "\n",
    "# print train data\n",
    "print(train_image)\n",
    "\n",
    "# create encoder and encode input\n",
    "encoder = RepeatEncoder(time=time, dt=dt)\n",
    "train_image = torch.FloatTensor([[80,70,60],[50,40,30],[20,10,0]])\n",
    "encoded_image = encoder(train_image)\n",
    "print(encoded_image)"
   ]
  },
  {
   "source": [
    "## 3c. Poisson Encoder\n",
    "\n",
    "Generates Poisson-distributed spike trains based on input intensity. Inputs must be non-negative, and give the firing rate in Hz. Inter-spike intervals (ISIs) for non-negative data incremented by one to avoid zero intervals while maintaining ISI distributions.\n",
    "\n",
    "### Limitations\n",
    "* Inputs must be non-negative\n",
    "* Inputs must be floating point numbers (otherwise the rate will zero out)\n",
    "\n",
    "### Rate Calculation\n",
    "\n",
    "1. Compute firing rates in seconds as a function of data intensity\n",
    "    * rate = (1 / input_intensity) * (1000 / dt)\n",
    "    * higher intensity -> lower inter-spike interaval\n",
    "    * dt = simulation time step\n",
    "2. Create Poisson distribution and sample inter-spike intervals\n",
    "    * A time/dt samples taken for each input element based on the probability density function (pdf) of a Poisson distribution\n",
    "        * Vales near the rate (lambda) more likely to occur\n",
    "        * The higher the rate, the more varied the data will be\n",
    "    * if any samples produced 0, set them to 1\n",
    "3. Add all of the samples generated for each input element\n",
    "    * if any samples are greater than time/dt, set them to 0\n",
    "4. Create tensor of spikes\n",
    "    * Given an input tensor with dimsnions X x Y, the output tensor has dimensions (time/dt + 1) x X x Y\n",
    "\n",
    "\n",
    "### Poisson Distribution\n",
    "\n",
    "![Poisson Probability Function](https://wikimedia.org/api/rest_v1/media/math/render/svg/c22cb4461e100a6db5f815de1f44b1747f160048)\n",
    "\n",
    "![Poisson Probability Graph Function](https://upload.wikimedia.org/wikipedia/commons/thumb/1/16/Poisson_pmf.svg/325px-Poisson_pmf.svg.png)\n",
    "\n",
    "where\n",
    "* k is the number of occurrences\n",
    "* Î» is the rate (mean number of occurrences in the interval)\n",
    "\n",
    "(Source [wikipedia.org](https://en.wikipedia.org/wiki/Poisson_distribution))"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[80., 70., 60.],\n        [50., 40., 30.],\n        [20., 10.,  0.]])\ntensor([[[0, 0, 0],\n         [0, 0, 0],\n         [0, 0, 0]],\n\n        [[0, 0, 0],\n         [0, 0, 0],\n         [0, 0, 0]],\n\n        [[0, 0, 0],\n         [0, 0, 0],\n         [0, 0, 0]],\n\n        [[0, 0, 0],\n         [0, 0, 0],\n         [0, 0, 0]],\n\n        [[0, 0, 0],\n         [0, 0, 0],\n         [0, 0, 0]],\n\n        [[0, 0, 0],\n         [0, 0, 0],\n         [0, 0, 0]],\n\n        [[0, 0, 0],\n         [0, 0, 0],\n         [0, 0, 0]],\n\n        [[0, 0, 0],\n         [0, 0, 0],\n         [0, 0, 0]],\n\n        [[0, 0, 0],\n         [0, 0, 0],\n         [0, 0, 0]],\n\n        [[0, 0, 0],\n         [0, 0, 0],\n         [0, 0, 0]]], dtype=torch.uint8)\n"
     ]
    }
   ],
   "source": [
    "# time is the total sample duration in ms\n",
    "time = 10\n",
    "\n",
    "# dt is the step size within the sample duration in ms\n",
    "dt = 1.0\n",
    "\n",
    "# input data\n",
    "train_image = torch.FloatTensor([[80,70,60],[50,40,30],[20,10,0]])\n",
    "\n",
    "# print train data\n",
    "print(train_image)\n",
    "\n",
    "# create encoder and encode input\n",
    "encoder = PoissonEncoder(time=time, dt=dt)\n",
    "encoded_image = encoder(train_image)\n",
    "print(encoded_image)"
   ]
  },
  {
   "source": [
    "## 3d. Bernoulli Encoder"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[80., 70., 60.],\n        [50., 40., 30.],\n        [20., 10.,  0.]])\ntensor([[[1, 1, 1],\n         [0, 1, 1],\n         [1, 0, 0]],\n\n        [[1, 1, 1],\n         [1, 1, 0],\n         [0, 0, 0]],\n\n        [[1, 1, 1],\n         [0, 1, 0],\n         [0, 0, 0]],\n\n        [[1, 1, 0],\n         [1, 0, 0],\n         [0, 0, 0]],\n\n        [[1, 1, 1],\n         [1, 0, 0],\n         [1, 0, 0]],\n\n        [[1, 1, 1],\n         [0, 0, 0],\n         [0, 0, 0]],\n\n        [[1, 1, 1],\n         [1, 1, 1],\n         [0, 1, 0]],\n\n        [[1, 1, 1],\n         [0, 0, 1],\n         [0, 0, 0]],\n\n        [[1, 1, 0],\n         [1, 0, 0],\n         [0, 1, 0]],\n\n        [[1, 1, 1],\n         [1, 0, 0],\n         [0, 0, 0]]], dtype=torch.uint8)\n"
     ]
    }
   ],
   "source": [
    "# time is the total sample duration in ms\n",
    "time = 10\n",
    "\n",
    "# dt is the step size within the sample duration in ms\n",
    "dt = 1.0\n",
    "\n",
    "# input data\n",
    "train_image = torch.FloatTensor([[80,70,60],[50,40,30],[20,10,0]])\n",
    "\n",
    "# print train data\n",
    "print(train_image)\n",
    "\n",
    "# create encoder and encode input\n",
    "encoder = BernoulliEncoder(time=time, dt=dt)\n",
    "encoded_image = encoder(train_image)\n",
    "print(encoded_image)"
   ]
  },
  {
   "source": [
    "## 3e. Rank Order Encoder\n",
    "* data with the same value will spike at the same time\n",
    "* first: data scaled based on the max value\n",
    "* times array created with highest value having value of 1 and lowest value closer to inf\n",
    "* time array multiplied by num timesteps / max value in time array\n",
    "* values are rounded up to next whole number\n",
    "* spike array created n elements for each timestep\n",
    "* iterate through each element i\n",
    "* if the rank for i is within the time number of timesteps\n",
    "* add a spike for this element wherever the spike is supposed to occur\n",
    "* the close the data is to 0, the higher (later) the rank will be"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[80., 70., 60.],\n        [50., 40., 30.],\n        [20., 10.,  0.]])\ntensor([[[0, 0, 0],\n         [0, 0, 0],\n         [0, 0, 0]],\n\n        [[1, 1, 1],\n         [1, 0, 0],\n         [0, 0, 0]],\n\n        [[0, 0, 0],\n         [0, 1, 0],\n         [0, 0, 0]],\n\n        [[0, 0, 0],\n         [0, 0, 1],\n         [0, 0, 0]],\n\n        [[0, 0, 0],\n         [0, 0, 0],\n         [1, 0, 0]],\n\n        [[0, 0, 0],\n         [0, 0, 0],\n         [0, 0, 0]],\n\n        [[0, 0, 0],\n         [0, 0, 0],\n         [0, 0, 0]],\n\n        [[0, 0, 0],\n         [0, 0, 0],\n         [0, 0, 0]],\n\n        [[0, 0, 0],\n         [0, 0, 0],\n         [0, 0, 0]],\n\n        [[0, 0, 0],\n         [0, 0, 0],\n         [0, 0, 0]]], dtype=torch.uint8)\n"
     ]
    }
   ],
   "source": [
    "# time is the total sample duration in ms\n",
    "time = 10\n",
    "\n",
    "# dt is the step size within the sample duration in ms\n",
    "dt = 1.0\n",
    "\n",
    "# input data\n",
    "train_image = torch.FloatTensor([[80,70,60],[50,40,30],[20,10,0]])\n",
    "\n",
    "# print train data\n",
    "print(train_image)\n",
    "\n",
    "# create encoder and encode input\n",
    "encoder = RankOrderEncoder(time=time, dt=dt)\n",
    "encoded_image = encoder(train_image)\n",
    "print(encoded_image)"
   ]
  }
 ]
}