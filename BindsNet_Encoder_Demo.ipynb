{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.5 64-bit",
   "display_name": "Python 3.8.5 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "5dd580b098b1a4c999aba16cc2250b4bc8a1753c772c29048a0e2694cf38a6c9"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# BindsNet Encoders\n",
    "\n",
    "## 1. Table of Contents\n",
    "1. Import Statements\n",
    "2. Encoders\n",
    "    1. Single Spike Encoders\n",
    "    2. Repeat Encoder\n",
    "    3. Poisson Encoders\n",
    "    4. Bernoulli Encoders\n",
    "    5. Rank Order Encoder"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 2. Import Statements"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from time import time as t\n",
    "\n",
    "from bindsnet.encoding import *"
   ]
  },
  {
   "source": [
    "## 1a. Single Spike Encoder\n",
    "* Inputs produces a single spike at time 0\n",
    "* sparsity argument is used to specify the cutoff point for spikes based on the quantile value\n",
    "* for a sparsity value s, the quantile is calculated at the 1 - s point\n",
    "* elements with value less than the quantile will not spike\n",
    "* the remaining elements will produce a spike at time 0 "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Single Encoder\")\n",
    "encoder = SingleEncoder(time=time, dt=dt,sparsity=1)\n",
    "train_image = torch.FloatTensor([[200,0,0],[0,200,0],[200,0,200]])\n",
    "encoded_image = encoder(train_image)\n",
    "print(train_image)\n",
    "print(encoded_image)"
   ]
  },
  {
   "source": [
    "## 1a. Repeat Encoder\n",
    "Repeats the same datum vector for time/dt timesteps\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Repeat Encoder\")\n",
    "encoder = RepeatEncoder(time=time, dt=dt)\n",
    "train_image = torch.FloatTensor([[200,0,200],[0,200,0],[200,0,200]])\n",
    "encoded_image = encoder(train_image)\n",
    "print(train_image)\n",
    "print(encoded_image)"
   ]
  },
  {
   "source": [
    "## 1c. Poisson Encoder"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding parameters\n",
    "# time for each sample (ms)\n",
    "time = 100\n",
    "# step size for the sample time (ms)\n",
    "dt = 1.0\n",
    "intensity = 128\n",
    "\n",
    "print(\"Poisson Encoder\")\n",
    "encoder = PoissonEncoder(time=time, dt=dt)\n",
    "# Need to use FloatTensor instead of IntTensor because value will zero out during encoding\n",
    "train_image = torch.FloatTensor([[200,0,200],[0,200,0],[200,0,200]])\n",
    "encoded_image = encoder(train_image)\n",
    "print(train_image)\n",
    "print(encoded_image)"
   ]
  },
  {
   "source": [
    "## 1d. Bernoulli Encoder"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print(\"Bernoulli Encoder\")\n",
    "encoder = BernoulliEncoder(time=time, dt=dt)\n",
    "train_image = torch.FloatTensor([[200,0,200],[0,200,0],[200,0,200]])\n",
    "encoded_image = encoder(train_image)\n",
    "print(train_image)\n",
    "print(encoded_image)\n"
   ]
  },
  {
   "source": [
    "## 1e. Rank Order Encoder\n",
    "* data with the same value will spike at the same time\n",
    "* first: data scaled based on the max value\n",
    "* times array created with highest value having value of 1 and lowest value closer to inf\n",
    "* time array multiplied by num timesteps / max value in time array\n",
    "* values are rounded up to next whole number\n",
    "* spike array created n elements for each timestep\n",
    "* iterate through each element i\n",
    "* if the rank for i is within the time number of timesteps\n",
    "* add a spike for this element wherever the spike is supposed to occur\n",
    "* the close the data is to 0, the higher (later) the rank will be"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Rank Order Encoder\")\n",
    "encoder = RankOrderEncoder(time=time, dt=dt)\n",
    "train_image = torch.FloatTensor([[200,0,200],[0,200,0],[200,0,200]])\n",
    "encoded_image = encoder(train_image)\n",
    "print(train_image)\n",
    "print(encoded_image)"
   ]
  }
 ]
}